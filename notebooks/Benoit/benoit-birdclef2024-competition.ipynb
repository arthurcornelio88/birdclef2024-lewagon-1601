{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029d14eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:56:40.499411Z",
     "iopub.status.busy": "2024-04-06T10:56:40.498754Z",
     "iopub.status.idle": "2024-04-06T10:56:40.509360Z",
     "shell.execute_reply": "2024-04-06T10:56:40.508102Z"
    },
    "papermill": {
     "duration": 0.022015,
     "end_time": "2024-04-06T10:56:40.511798",
     "exception": false,
     "start_time": "2024-04-06T10:56:40.489783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kaggle = True\n",
    "submission = True # change to True before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf6cad",
   "metadata": {
    "papermill": {
     "duration": 0.005568,
     "end_time": "2024-04-06T10:56:40.523362",
     "exception": false,
     "start_time": "2024-04-06T10:56:40.517794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c394642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:56:40.539869Z",
     "iopub.status.busy": "2024-04-06T10:56:40.538983Z",
     "iopub.status.idle": "2024-04-06T10:56:43.847479Z",
     "shell.execute_reply": "2024-04-06T10:56:43.846095Z"
    },
    "papermill": {
     "duration": 3.320787,
     "end_time": "2024-04-06T10:56:43.850099",
     "exception": false,
     "start_time": "2024-04-06T10:56:40.529312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tqdm.notebook import tqdm # loading bar\n",
    "from tqdm import tqdm # loading bar\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42c857",
   "metadata": {
    "papermill": {
     "duration": 0.006415,
     "end_time": "2024-04-06T10:56:43.862729",
     "exception": false,
     "start_time": "2024-04-06T10:56:43.856314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119b46e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:56:43.876017Z",
     "iopub.status.busy": "2024-04-06T10:56:43.875409Z",
     "iopub.status.idle": "2024-04-06T10:56:43.882636Z",
     "shell.execute_reply": "2024-04-06T10:56:43.881609Z"
    },
    "papermill": {
     "duration": 0.016859,
     "end_time": "2024-04-06T10:56:43.885151",
     "exception": false,
     "start_time": "2024-04-06T10:56:43.868292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if kaggle:\n",
    "    DATA_DIR = '../input/birdclef-2024/'\n",
    "else:\n",
    "    DATA_DIR = \"../../data/raw\" # local work\n",
    "    \n",
    "TRAIN_AUDIO_DIR = os.path.join(DATA_DIR, \"train_audio/\")\n",
    "\n",
    "if submission:\n",
    "    TEST_AUDIO_DIR = os.path.join(DATA_DIR,\"test_soundscapes/\")\n",
    "    \n",
    "else:\n",
    "    TEST_AUDIO_DIR = os.path.join(DATA_DIR,\"unlabeled_soundscapes/\")\n",
    "\n",
    "train_csv_path = os.path.join(DATA_DIR, \"train_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce829fc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:56:43.898728Z",
     "iopub.status.busy": "2024-04-06T10:56:43.898314Z",
     "iopub.status.idle": "2024-04-06T10:57:12.155698Z",
     "shell.execute_reply": "2024-04-06T10:57:12.154274Z"
    },
    "papermill": {
     "duration": 28.267623,
     "end_time": "2024-04-06T10:57:12.158722",
     "exception": false,
     "start_time": "2024-04-06T10:56:43.891099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Add complete filepath\n",
    "train_df['filepath'] = train_df.apply(lambda row: os.path.join(TRAIN_AUDIO_DIR, row['filename']), axis=1)\n",
    "\n",
    "# Filter out large files\n",
    "train_df['filesize'] = train_df.apply(lambda row: os.path.getsize(row['filepath']), axis=1)\n",
    "train_df = train_df[train_df['filesize'] < 1e6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb1fdca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:57:12.172212Z",
     "iopub.status.busy": "2024-04-06T10:57:12.171794Z",
     "iopub.status.idle": "2024-04-06T10:57:12.183612Z",
     "shell.execute_reply": "2024-04-06T10:57:12.182100Z"
    },
    "papermill": {
     "duration": 0.021236,
     "end_time": "2024-04-06T10:57:12.186054",
     "exception": false,
     "start_time": "2024-04-06T10:57:12.164818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_species = sorted(train_df.primary_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ea2dc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:57:12.200336Z",
     "iopub.status.busy": "2024-04-06T10:57:12.199616Z",
     "iopub.status.idle": "2024-04-06T10:57:12.864949Z",
     "shell.execute_reply": "2024-04-06T10:57:12.863197Z"
    },
    "papermill": {
     "duration": 0.675639,
     "end_time": "2024-04-06T10:57:12.867744",
     "exception": false,
     "start_time": "2024-04-06T10:57:12.192105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_state = 43\n",
    "\n",
    "if submission:\n",
    "    num_classes_to_keep = len(list_species)\n",
    "    fraction_to_keep = 0.5\n",
    "else:\n",
    "    num_classes_to_keep = 10\n",
    "    fraction_to_keep = 0.05\n",
    "\n",
    "# Calculate the minimum number of instances to keep for classes with fewer labels\n",
    "min_count = 50\n",
    "\n",
    "# Calculate weights to balance the classes\n",
    "class_weights = train_df['primary_label'].value_counts()\n",
    "\n",
    "# Select the top classes to keep based on their frequencies\n",
    "top_classes = class_weights.head(num_classes_to_keep).index.tolist()\n",
    "\n",
    "# Initialize an empty DataFrame to store the sampled subset\n",
    "train_subset_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each class\n",
    "for label, count in class_weights.items():\n",
    "    # Check if the class is in the top classes to keep\n",
    "    if label in top_classes:\n",
    "        # Check if the class has fewer labels than the minimum count\n",
    "        if count < min_count:\n",
    "            # Keep all instances for classes with fewer labels\n",
    "            subset = train_df[train_df['primary_label'] == label]\n",
    "        else:\n",
    "            # Randomly sample a fraction for classes with more labels\n",
    "            fraction = min(fraction_to_keep, min_count / count)  # Adjust fraction if necessary\n",
    "            subset = train_df[train_df['primary_label'] == label].sample(frac=fraction, random_state=random_state)\n",
    "        # Append the subset to the final DataFrame\n",
    "        train_subset_df = pd.concat([train_subset_df, subset])\n",
    "\n",
    "# Shuffle the final DataFrame to mix the classes\n",
    "train_subset_df = train_subset_df.sample(frac=1, random_state=random_state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71304e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:57:12.882444Z",
     "iopub.status.busy": "2024-04-06T10:57:12.882056Z",
     "iopub.status.idle": "2024-04-06T10:57:12.894228Z",
     "shell.execute_reply": "2024-04-06T10:57:12.893028Z"
    },
    "papermill": {
     "duration": 0.022488,
     "end_time": "2024-04-06T10:57:12.896089",
     "exception": false,
     "start_time": "2024-04-06T10:57:12.873601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_label\n",
       "eurcoo     50\n",
       "grewar3    50\n",
       "wemhar1    50\n",
       "comgre     50\n",
       "labcro1    50\n",
       "           ..\n",
       "blaeag1     6\n",
       "wynlau1     6\n",
       "integr      5\n",
       "asiope1     5\n",
       "niwpig1     5\n",
       "Name: count, Length: 182, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset_df['primary_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ff7f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:57:12.909210Z",
     "iopub.status.busy": "2024-04-06T10:57:12.908815Z",
     "iopub.status.idle": "2024-04-06T10:57:12.917198Z",
     "shell.execute_reply": "2024-04-06T10:57:12.915217Z"
    },
    "papermill": {
     "duration": 0.018125,
     "end_time": "2024-04-06T10:57:12.919923",
     "exception": false,
     "start_time": "2024-04-06T10:57:12.901798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if submission: # No train val split\n",
    "    X_train_files = train_subset_df.filepath\n",
    "    y_train = train_subset_df.primary_label\n",
    "else:\n",
    "    # Train val split\n",
    "    train_train_df, val_df = train_test_split(train_subset_df, test_size=0.3, stratify = train_subset_df.primary_label, random_state=random_state) \n",
    "    X_train_files = train_train_df.filepath\n",
    "    X_val_files = val_df.filepath\n",
    "\n",
    "    y_train = train_train_df.primary_label\n",
    "    y_val = val_df.primary_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2edf2",
   "metadata": {
    "papermill": {
     "duration": 0.006623,
     "end_time": "2024-04-06T10:57:12.933975",
     "exception": false,
     "start_time": "2024-04-06T10:57:12.927352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1727247f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:57:12.948667Z",
     "iopub.status.busy": "2024-04-06T10:57:12.948239Z",
     "iopub.status.idle": "2024-04-06T10:57:12.957067Z",
     "shell.execute_reply": "2024-04-06T10:57:12.955095Z"
    },
    "papermill": {
     "duration": 0.019898,
     "end_time": "2024-04-06T10:57:12.960597",
     "exception": false,
     "start_time": "2024-04-06T10:57:12.940699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_data, sample_rate=32000, mfcc=True, chroma=True, mel=True):\n",
    "    result = np.array([])\n",
    "    if mfcc: # Mel-Frequency Cepstral Coefficients\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=audio_data, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=audio_data, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb9f211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:57:12.977839Z",
     "iopub.status.busy": "2024-04-06T10:57:12.977120Z",
     "iopub.status.idle": "2024-04-06T10:57:12.984808Z",
     "shell.execute_reply": "2024-04-06T10:57:12.983084Z"
    },
    "papermill": {
     "duration": 0.020011,
     "end_time": "2024-04-06T10:57:12.987805",
     "exception": false,
     "start_time": "2024-04-06T10:57:12.967794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features_filepaths(X_files, sample_rate=32000):\n",
    "    features = []\n",
    "    \n",
    "    for filepath in tqdm(X_files, desc='Processing files', total=len(X_files)):\n",
    "        # Process data with tqdm\n",
    "        audio_data, _ = librosa.load(filepath, sr=sample_rate)\n",
    "        audio_features = extract_features(audio_data, sample_rate)\n",
    "\n",
    "        # Append features and label\n",
    "        features.append(audio_features)\n",
    "            \n",
    "    X = np.array(features)  \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5caea1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T10:57:13.002312Z",
     "iopub.status.busy": "2024-04-06T10:57:13.001902Z",
     "iopub.status.idle": "2024-04-06T11:24:05.246615Z",
     "shell.execute_reply": "2024-04-06T11:24:05.245741Z"
    },
    "papermill": {
     "duration": 1612.257683,
     "end_time": "2024-04-06T11:24:05.252036",
     "exception": false,
     "start_time": "2024-04-06T10:57:12.994353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  16%|█▌        | 1036/6615 [04:18<18:01,  5.16it/s]/opt/conda/lib/python3.10/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Processing files: 100%|██████████| 6615/6615 [26:52<00:00,  4.10it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = extract_features_filepaths(X_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cfee670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:24:05.938437Z",
     "iopub.status.busy": "2024-04-06T11:24:05.937292Z",
     "iopub.status.idle": "2024-04-06T11:24:05.950358Z",
     "shell.execute_reply": "2024-04-06T11:24:05.948525Z"
    },
    "papermill": {
     "duration": 0.351515,
     "end_time": "2024-04-06T11:24:05.953223",
     "exception": false,
     "start_time": "2024-04-06T11:24:05.601708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff6854d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:24:06.670529Z",
     "iopub.status.busy": "2024-04-06T11:24:06.670170Z",
     "iopub.status.idle": "2024-04-06T11:24:06.677305Z",
     "shell.execute_reply": "2024-04-06T11:24:06.676024Z"
    },
    "papermill": {
     "duration": 0.383468,
     "end_time": "2024-04-06T11:24:06.679803",
     "exception": false,
     "start_time": "2024-04-06T11:24:06.296335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_val = extract_features_filepaths(X_val_files)\n",
    "# y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efe551",
   "metadata": {
    "papermill": {
     "duration": 0.430891,
     "end_time": "2024-04-06T11:24:07.464949",
     "exception": false,
     "start_time": "2024-04-06T11:24:07.034058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18122fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:24:08.142943Z",
     "iopub.status.busy": "2024-04-06T11:24:08.142532Z",
     "iopub.status.idle": "2024-04-06T11:25:34.145306Z",
     "shell.execute_reply": "2024-04-06T11:25:34.143587Z"
    },
    "papermill": {
     "duration": 86.681857,
     "end_time": "2024-04-06T11:25:34.483795",
     "exception": false,
     "start_time": "2024-04-06T11:24:07.801938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=2, n_estimators=300,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=2, n_estimators=300,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, min_samples_leaf=2, n_estimators=300,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier with the best parameters\n",
    "best_classifier = RandomForestClassifier(max_depth=20, min_samples_leaf=2, n_estimators=300, random_state=42)\n",
    "best_classifier.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f951e2ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:25:35.237413Z",
     "iopub.status.busy": "2024-04-06T11:25:35.236686Z",
     "iopub.status.idle": "2024-04-06T11:25:35.242103Z",
     "shell.execute_reply": "2024-04-06T11:25:35.240420Z"
    },
    "papermill": {
     "duration": 0.423824,
     "end_time": "2024-04-06T11:25:35.244528",
     "exception": false,
     "start_time": "2024-04-06T11:25:34.820704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_val_pred_proba = best_classifier.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3cb1f6",
   "metadata": {
    "papermill": {
     "duration": 0.352611,
     "end_time": "2024-04-06T11:25:35.926755",
     "exception": false,
     "start_time": "2024-04-06T11:25:35.574144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "613446f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:25:36.631126Z",
     "iopub.status.busy": "2024-04-06T11:25:36.630405Z",
     "iopub.status.idle": "2024-04-06T11:25:36.636009Z",
     "shell.execute_reply": "2024-04-06T11:25:36.635141Z"
    },
    "papermill": {
     "duration": 0.360214,
     "end_time": "2024-04-06T11:25:36.638528",
     "exception": false,
     "start_time": "2024-04-06T11:25:36.278314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_numbers(filename):\n",
    "    filename = filename.split('.')[0] # remove extension\n",
    "    \n",
    "    split = filename.split('_')\n",
    "    \n",
    "    if len(split) > 1:\n",
    "        return split[1]\n",
    "    elif len(split) == 1:\n",
    "        return split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d50064fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:25:37.344983Z",
     "iopub.status.busy": "2024-04-06T11:25:37.344220Z",
     "iopub.status.idle": "2024-04-06T11:25:37.503047Z",
     "shell.execute_reply": "2024-04-06T11:25:37.501010Z"
    },
    "papermill": {
     "duration": 0.520828,
     "end_time": "2024-04-06T11:25:37.505924",
     "exception": false,
     "start_time": "2024-04-06T11:25:36.985096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test files: 5\n"
     ]
    }
   ],
   "source": [
    "# First, load list of audio files by parsing the test_soundscape folder.\n",
    "test_file_list = sorted(os.listdir(TEST_AUDIO_DIR))\n",
    "test_file_list = [file for file in test_file_list if file.endswith('.ogg')] # filter only ogg files\n",
    "\n",
    "if len(test_file_list) == 0:  # for debugging purposes when not submitting\n",
    "    TEST_AUDIO_DIR = os.path.join(DATA_DIR,\"unlabeled_soundscapes/\")\n",
    "    test_file_list = sorted(os.listdir(TEST_AUDIO_DIR))\n",
    "    test_file_list = [file for file in test_file_list if file.endswith('.ogg')] # filter only ogg files\n",
    "    test_file_list = test_file_list[:5] # take only 5 elements to go faster on debugging\n",
    "\n",
    "test_number_list = [extract_numbers(file) for file in test_file_list]\n",
    "    \n",
    "print(f'Number of test files: {len(test_file_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3109929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:25:38.259092Z",
     "iopub.status.busy": "2024-04-06T11:25:38.258611Z",
     "iopub.status.idle": "2024-04-06T11:25:38.265294Z",
     "shell.execute_reply": "2024-04-06T11:25:38.263763Z"
    },
    "papermill": {
     "duration": 0.349117,
     "end_time": "2024-04-06T11:25:38.268078",
     "exception": false,
     "start_time": "2024-04-06T11:25:37.918961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to split audio file into chunks of given duration\n",
    "def split_audio(path, duration, sr):\n",
    "    sig, rate = librosa.load(path, sr=sr)\n",
    "    chunk_size = duration * rate\n",
    "    chunks = [sig[i:i+chunk_size] for i in range(0, len(sig), chunk_size)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1d14c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:25:38.954127Z",
     "iopub.status.busy": "2024-04-06T11:25:38.953787Z",
     "iopub.status.idle": "2024-04-06T11:25:50.557821Z",
     "shell.execute_reply": "2024-04-06T11:25:50.557034Z"
    },
    "papermill": {
     "duration": 11.952544,
     "end_time": "2024-04-06T11:25:50.560121",
     "exception": false,
     "start_time": "2024-04-06T11:25:38.607577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test files: 100%|██████████| 5/5 [00:11<00:00,  2.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# This is where we will store our results\n",
    "row_id_list = []\n",
    "X_test = []\n",
    "\n",
    "# Process audio files and make predictions with tqdm progress bar\n",
    "for audio_file, file_number in tqdm(zip(test_file_list, test_number_list), total=len(test_file_list), desc='Processing test files'):\n",
    "    path = os.path.join(TEST_AUDIO_DIR, audio_file)\n",
    "        \n",
    "    # Split audio file into 5-second chunks\n",
    "    audio_chunks = split_audio(path, duration=5, sr=32000)\n",
    "    \n",
    "    for i in range(48): # assuming files of 4 minutes = 240 seconds\n",
    "    # for i, chunk in enumerate(audio_chunks):\n",
    "        chunk = audio_chunks[i]\n",
    "        chunk_end_time = (i + 1) * 5\n",
    "        row_id = f\"soundscape_{file_number}_{chunk_end_time}\"\n",
    "        row_id_list.append(row_id)\n",
    "        \n",
    "        features = extract_features(chunk)\n",
    "        \n",
    "        X_test.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c73549d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:25:51.358155Z",
     "iopub.status.busy": "2024-04-06T11:25:51.357800Z",
     "iopub.status.idle": "2024-04-06T11:25:51.409664Z",
     "shell.execute_reply": "2024-04-06T11:25:51.408014Z"
    },
    "papermill": {
     "duration": 0.395652,
     "end_time": "2024-04-06T11:25:51.412659",
     "exception": false,
     "start_time": "2024-04-06T11:25:51.017007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = np.array(X_test) # convert list of 1D arrays to 2D array\n",
    "\n",
    "if len(X_test) > 0:\n",
    "    y_pred_proba = best_classifier.predict_proba(X_test)\n",
    "else:\n",
    "    y_pred_proba = [0 for class_ in label_encoder.classes_] # just for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86ced1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:25:52.076083Z",
     "iopub.status.busy": "2024-04-06T11:25:52.075603Z",
     "iopub.status.idle": "2024-04-06T11:25:52.195939Z",
     "shell.execute_reply": "2024-04-06T11:25:52.192876Z"
    },
    "papermill": {
     "duration": 0.456296,
     "end_time": "2024-04-06T11:25:52.199962",
     "exception": false,
     "start_time": "2024-04-06T11:25:51.743666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n",
      "/tmp/ipykernel_18/533116554.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results[label_encoder.classes_] = y_pred_proba\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>asbfly</th>\n",
       "      <th>ashdro1</th>\n",
       "      <th>ashpri1</th>\n",
       "      <th>ashwoo2</th>\n",
       "      <th>asikoe2</th>\n",
       "      <th>asiope1</th>\n",
       "      <th>aspfly1</th>\n",
       "      <th>aspswi1</th>\n",
       "      <th>barfly1</th>\n",
       "      <th>...</th>\n",
       "      <th>whbwoo2</th>\n",
       "      <th>whcbar1</th>\n",
       "      <th>whiter2</th>\n",
       "      <th>whrmun</th>\n",
       "      <th>whtkin2</th>\n",
       "      <th>woosan</th>\n",
       "      <th>wynlau1</th>\n",
       "      <th>yebbab1</th>\n",
       "      <th>yebbul3</th>\n",
       "      <th>zitcis1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_1000170626_5</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.043256</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.002770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_1000170626_10</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.005184</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.047011</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.004085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_1000170626_15</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.030601</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.004471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_1000170626_20</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.032571</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.004561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_1000170626_25</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.039973</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.004596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>soundscape_1000450112_220</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.004145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>soundscape_1000450112_225</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.004105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>soundscape_1000450112_230</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.004062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>soundscape_1000450112_235</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.004041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>soundscape_1000450112_240</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.004034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        row_id    asbfly   ashdro1   ashpri1   ashwoo2  \\\n",
       "0      soundscape_1000170626_5  0.003522  0.014063  0.007287  0.004493   \n",
       "1     soundscape_1000170626_10  0.004504  0.016342  0.006306  0.005184   \n",
       "2     soundscape_1000170626_15  0.003797  0.006256  0.009692  0.004934   \n",
       "3     soundscape_1000170626_20  0.003871  0.008815  0.005320  0.005506   \n",
       "4     soundscape_1000170626_25  0.003751  0.006400  0.009537  0.003829   \n",
       "..                         ...       ...       ...       ...       ...   \n",
       "235  soundscape_1000450112_220  0.006019  0.004152  0.005088  0.003037   \n",
       "236  soundscape_1000450112_225  0.006126  0.005980  0.005381  0.002514   \n",
       "237  soundscape_1000450112_230  0.006413  0.004018  0.005351  0.002567   \n",
       "238  soundscape_1000450112_235  0.006401  0.003869  0.005128  0.002459   \n",
       "239  soundscape_1000450112_240  0.005937  0.004252  0.006642  0.003218   \n",
       "\n",
       "      asikoe2   asiope1   aspfly1   aspswi1   barfly1  ...   whbwoo2  \\\n",
       "0    0.002801  0.000398  0.002887  0.003057  0.001515  ...  0.002275   \n",
       "1    0.002700  0.000282  0.003746  0.003297  0.001310  ...  0.002079   \n",
       "2    0.003045  0.000520  0.003754  0.003779  0.001646  ...  0.002446   \n",
       "3    0.003091  0.000325  0.003213  0.004353  0.001644  ...  0.002293   \n",
       "4    0.002991  0.000310  0.003582  0.004513  0.001564  ...  0.002325   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "235  0.003189  0.004419  0.002925  0.001760  0.001321  ...  0.006437   \n",
       "236  0.003258  0.004439  0.002801  0.001893  0.001335  ...  0.005600   \n",
       "237  0.003249  0.004431  0.002854  0.001914  0.001563  ...  0.005558   \n",
       "238  0.003222  0.003320  0.002704  0.001883  0.001296  ...  0.005407   \n",
       "239  0.003035  0.003281  0.002816  0.002305  0.001273  ...  0.003007   \n",
       "\n",
       "      whcbar1   whiter2    whrmun   whtkin2    woosan   wynlau1   yebbab1  \\\n",
       "0    0.001502  0.005354  0.006488  0.003125  0.043256  0.001793  0.001186   \n",
       "1    0.001343  0.005722  0.006560  0.002991  0.047011  0.001760  0.001184   \n",
       "2    0.001597  0.006192  0.003488  0.002805  0.030601  0.002155  0.001180   \n",
       "3    0.001596  0.006329  0.004611  0.003217  0.032571  0.002249  0.001323   \n",
       "4    0.001517  0.006196  0.003595  0.002965  0.039973  0.002356  0.001179   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "235  0.006090  0.005595  0.005764  0.006686  0.012849  0.001482  0.001302   \n",
       "236  0.006335  0.005407  0.002706  0.006509  0.011552  0.001284  0.001064   \n",
       "237  0.006351  0.005500  0.002433  0.006769  0.011246  0.001221  0.001033   \n",
       "238  0.006365  0.005437  0.002634  0.008286  0.010563  0.001243  0.001060   \n",
       "239  0.006159  0.005596  0.002542  0.008208  0.012930  0.001451  0.001198   \n",
       "\n",
       "      yebbul3   zitcis1  \n",
       "0    0.000993  0.002770  \n",
       "1    0.000922  0.004085  \n",
       "2    0.000906  0.004471  \n",
       "3    0.001093  0.004561  \n",
       "4    0.000906  0.004596  \n",
       "..        ...       ...  \n",
       "235  0.001378  0.004145  \n",
       "236  0.001549  0.004105  \n",
       "237  0.001630  0.004062  \n",
       "238  0.001533  0.004041  \n",
       "239  0.001172  0.004034  \n",
       "\n",
       "[240 rows x 183 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'row_id':row_id_list})\n",
    "results[label_encoder.classes_] = y_pred_proba\n",
    "\n",
    "# Update the order of the columns to be ordered, and to contain all species\n",
    "columns_order = ['row_id'] + list_species\n",
    "\n",
    "results = results.reindex(columns=columns_order).fillna(0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47b2ad2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-06T11:25:52.872124Z",
     "iopub.status.busy": "2024-04-06T11:25:52.870363Z",
     "iopub.status.idle": "2024-04-06T11:25:52.946049Z",
     "shell.execute_reply": "2024-04-06T11:25:52.944541Z"
    },
    "papermill": {
     "duration": 0.414276,
     "end_time": "2024-04-06T11:25:52.948487",
     "exception": false,
     "start_time": "2024-04-06T11:25:52.534211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert our results to csv\n",
    "results.to_csv(\"submission.csv\", index=False)  "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1758.298663,
   "end_time": "2024-04-06T11:25:55.965203",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-06T10:56:37.666540",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
